{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a simple notebook to build and visualize decision trees.\n",
    "\n",
    "Author: Viviana Acquaviva\n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/).\n",
    "    \n",
    "Some visualization-inspiration credits:\n",
    "\n",
    "https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "\n",
    "https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd #to load data into a data frame\n",
    "\n",
    "from sklearn.model_selection import train_test_split #we don't use it here, but it's a useful function!\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #how methods are imported \n",
    "\n",
    "from sklearn import metrics #this will give us access to evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a bunch of packages for visualization purposes only - this cell can be skipped if troublesome\n",
    "\n",
    "from io import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use a selection of data from https://phl.upr.edu/projects/habitable-exoplanets-catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We begin by reading in the data set using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet = pd.read_csv('HPLearningSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet = LearningSet.drop(LearningSet.columns[0], axis=1) #We want to drop the first column of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure we created is called a data frame.\n",
    "\n",
    "It's nice because we can refer to columns with their names as well as indices, and it looks neat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's pick the same train/test set we had in the slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of \".iloc\" (integer location) to access indices in data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet =  LearningSet.iloc[:13,:]  #normally this would happen at random, using the function train_test_split\n",
    "\n",
    "TestSet = LearningSet.iloc[13:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We split the train and test sets in features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = TrainSet.drop(['P_NAME','P_HABITABLE'],axis=1)\n",
    "\n",
    "Xtest = TestSet.drop(['P_NAME','P_HABITABLE'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = TrainSet.P_HABITABLE\n",
    "\n",
    "ytest = TestSet.P_HABITABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we are ready to fit the model with our decision tree!\n",
    "\n",
    "Note: The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. \n",
    "\n",
    "To obtain a deterministic behaviour during fitting, random_state has to be fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 3) #This is how we specify which method we'd like to use, and any parameters.\n",
    "\n",
    "model.fit(Xtrain, ytrain) #This tiny line is how we build models in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we can visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            model,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'],\n",
    "            class_names = ['Not Habitable','Habitable'],\n",
    "            filled = True,\n",
    "            rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "nodes = graph.get_node_list()\n",
    "\n",
    "for node in nodes:\n",
    "    if node.get_label():\n",
    "        values = [int(ii) for ii in node.get_label().split('value = [')[1].split(']')[0].split(',')]\n",
    "        values = [255 * v / sum(values) for v in values]\n",
    "        \n",
    "        values = [int(255 * v / sum(values)) for v in values]\n",
    "            \n",
    "        if values[0] > values[1]:\n",
    "            alpha = int(values[0] - values[1])\n",
    "            alpha = '{:02x}'.format(alpha) #turn into hexadecimal\n",
    "            color = '#20 B2 AA'+str(alpha)\n",
    "        else:\n",
    "            alpha = int(values[1] - values[0])\n",
    "            alpha = '{:02x}'.format(alpha)\n",
    "            color = '#FF 00 FF'+str(alpha)\n",
    "        node.set_fillcolor(color)\n",
    "\n",
    "graph.set_dpi('300')\n",
    "\n",
    "Image(graph.create_png())\n",
    "\n",
    "#Image(graph.write_png('Graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an alternative visualization, which only relies on the sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(40,20))  # customize according to the size of your tree\n",
    "\n",
    "tree.plot_tree(model, feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'], class_names = ['Not Habitable','Habitable'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can visualize the splits as well and then answer some questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "\n",
    "#Will now plot the train set and test set points\n",
    "\n",
    "plt.scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], marker = '*',\\\n",
    "            c = TrainSet['P_HABITABLE'], s = 100, cmap=cmap, label = 'Train')\n",
    "\n",
    "plt.scatter(TestSet['S_MASS'], TestSet['P_PERIOD'], marker = 'o',\\\n",
    "            c = TestSet['P_HABITABLE'], s = 100, cmap=cmap, label = 'Test')\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "#I can add the splits to the plot\n",
    "\n",
    "plt.axvline(x=0.83, linewidth =1, ls = '-', label = '1st split', c='k')\n",
    "\n",
    "plt.axhline(y=4.891, xmin = 0, xmax = 0.655, linewidth =1, ls = '--', label = '2nd split',c='k')\n",
    "\n",
    "plt.text(0.845, 10**3, '1st split', fontsize=14)\n",
    "         \n",
    "plt.text(0.65, 6, '2nd split', fontsize=14)\n",
    "\n",
    "#Add legend, including unlabeled objects\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable')\n",
    "\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "predhab = mpatches.Rectangle((0,4.891),0.83,ax.get_ylim()[1], \n",
    "                        fill = True,\n",
    "                        color = '#FF00FF',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "prednothab1 = mpatches.Rectangle((0.83,ax.get_ylim()[0]),ax.get_xlim()[1],ax.get_ylim()[1], \n",
    "                        fill = True,\n",
    "                        color = '#20B2AA',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "prednothab2 = mpatches.Rectangle((0,ax.get_ylim()[0]),0.83,4.891-ax.get_ylim()[0], \n",
    "                        fill = True,\n",
    "                        color = '#20B2AA',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[2].set_color('k')\n",
    "leg.legendHandles[3].set_color('k')\n",
    "\n",
    "plt.gca().add_patch(predhab)\n",
    "plt.gca().add_patch(prednothab1)\n",
    "plt.gca().add_patch(prednothab2)\n",
    "\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[2].set_color('k')\n",
    "leg.legendHandles[3].set_color('k')\n",
    "\n",
    "\n",
    "plt.legend(handles=[leg.legendHandles[2],leg.legendHandles[3], magentapatch, bluepatch],\\\n",
    "           loc = 'upper left', fontsize = 14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: \n",
    "    \n",
    "- What is the accuracy (percentage of correct classifications) on the training set? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- How about on the test set (you have to run the test example through the tree, or look at the figure above)? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want, of course, to be able to answer the questions in code as well.\n",
    "\n",
    "ypred_train = ....\n",
    "\n",
    "ypred_test = ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(.... ) #test score, or comparison of\n",
    "#real labels on test set with predicted labels on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(.... ) #train score, or comparison of\n",
    "#real labels on train set with predicted labels on train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our final reflection will be an exercise in picking a different train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pick the first 5 objects for test, objects 5:18 for training;\n",
    "\n",
    "- Build the train and test sets, for features and labels;\n",
    "\n",
    "- Build a decision tree model on the new train set;\n",
    "\n",
    "- Visualize the new tree;\n",
    "\n",
    "- Calculate the train and test scores for this new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's draw some conclusions together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Strengths of DT algorithm?\n",
    "\n",
    "- Limitations?\n",
    "\n",
    "- Possible concerns?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
